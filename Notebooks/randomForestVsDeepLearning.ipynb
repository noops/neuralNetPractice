{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit ('PythonData': conda)",
   "display_name": "Python 3.7.7 64-bit ('PythonData': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6629937ca33c91e24171fb9c2c6e8adc4c28b335a7e363e22452b0d874202ae3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "random forests will only handle tabular data while neural networks cna handle all sorts of data types. A random forest model with a sufficient number of estimators and tree depth should be able to perform at a similar capacity to most deep learning models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import tensorflow as tf\n",
    "from path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  Loan_Status  Current_Loan_Amount        Term  Credit_Score  Annual_Income  \\\n0  Fully_Paid             99999999  Short_Term         741.0      2231892.0   \n1  Fully_Paid               217646  Short_Term         730.0      1184194.0   \n2  Fully_Paid               548746  Short_Term         678.0      2559110.0   \n3  Fully_Paid             99999999  Short_Term         728.0       714628.0   \n4  Fully_Paid             99999999  Short_Term         740.0       776188.0   \n\n  Years_in_current_job Home_Ownership             Purpose  Monthly_Debt  \\\n0              8_years       Own_Home  Debt_Consolidation      29200.53   \n1             &lt;_1_year  Home_Mortgage  Debt_Consolidation      10855.08   \n2              2_years           Rent  Debt_Consolidation      18660.28   \n3              3_years           Rent  Debt_Consolidation      11851.06   \n4             &lt;_1_year       Own_Home  Debt_Consolidation      11578.22   \n\n   Years_of_Credit_History  Months_since_last_delinquent  \\\n0                     14.9                          29.0   \n1                     19.6                          10.0   \n2                     22.6                          33.0   \n3                     16.0                          76.0   \n4                      8.5                          25.0   \n\n   Number_of_Open_Accounts  Number_of_Credit_Problems  Current_Credit_Balance  \\\n0                       18                          1                  297996   \n1                       13                          1                  122170   \n2                        4                          0                  437171   \n3                       16                          0                  203965   \n4                        6                          0                  134083   \n\n   Maximum_Open_Credit  Bankruptcies  Tax_Liens  \n0             750090.0           0.0        0.0  \n1             272052.0           1.0        0.0  \n2             555038.0           0.0        0.0  \n3             289784.0           0.0        0.0  \n4             220220.0           0.0        0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loan_Status</th>\n      <th>Current_Loan_Amount</th>\n      <th>Term</th>\n      <th>Credit_Score</th>\n      <th>Annual_Income</th>\n      <th>Years_in_current_job</th>\n      <th>Home_Ownership</th>\n      <th>Purpose</th>\n      <th>Monthly_Debt</th>\n      <th>Years_of_Credit_History</th>\n      <th>Months_since_last_delinquent</th>\n      <th>Number_of_Open_Accounts</th>\n      <th>Number_of_Credit_Problems</th>\n      <th>Current_Credit_Balance</th>\n      <th>Maximum_Open_Credit</th>\n      <th>Bankruptcies</th>\n      <th>Tax_Liens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Fully_Paid</td>\n      <td>99999999</td>\n      <td>Short_Term</td>\n      <td>741.0</td>\n      <td>2231892.0</td>\n      <td>8_years</td>\n      <td>Own_Home</td>\n      <td>Debt_Consolidation</td>\n      <td>29200.53</td>\n      <td>14.9</td>\n      <td>29.0</td>\n      <td>18</td>\n      <td>1</td>\n      <td>297996</td>\n      <td>750090.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Fully_Paid</td>\n      <td>217646</td>\n      <td>Short_Term</td>\n      <td>730.0</td>\n      <td>1184194.0</td>\n      <td>&lt;_1_year</td>\n      <td>Home_Mortgage</td>\n      <td>Debt_Consolidation</td>\n      <td>10855.08</td>\n      <td>19.6</td>\n      <td>10.0</td>\n      <td>13</td>\n      <td>1</td>\n      <td>122170</td>\n      <td>272052.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Fully_Paid</td>\n      <td>548746</td>\n      <td>Short_Term</td>\n      <td>678.0</td>\n      <td>2559110.0</td>\n      <td>2_years</td>\n      <td>Rent</td>\n      <td>Debt_Consolidation</td>\n      <td>18660.28</td>\n      <td>22.6</td>\n      <td>33.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>437171</td>\n      <td>555038.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Fully_Paid</td>\n      <td>99999999</td>\n      <td>Short_Term</td>\n      <td>728.0</td>\n      <td>714628.0</td>\n      <td>3_years</td>\n      <td>Rent</td>\n      <td>Debt_Consolidation</td>\n      <td>11851.06</td>\n      <td>16.0</td>\n      <td>76.0</td>\n      <td>16</td>\n      <td>0</td>\n      <td>203965</td>\n      <td>289784.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fully_Paid</td>\n      <td>99999999</td>\n      <td>Short_Term</td>\n      <td>740.0</td>\n      <td>776188.0</td>\n      <td>&lt;_1_year</td>\n      <td>Own_Home</td>\n      <td>Debt_Consolidation</td>\n      <td>11578.22</td>\n      <td>8.5</td>\n      <td>25.0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>134083</td>\n      <td>220220.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "#load data\n",
    "file_path = Path(\"../Resources/loan_status.csv\")\n",
    "loans_df = pd.read_csv(file_path)\n",
    "loans_df.head()"
   ]
  },
  {
   "source": [
    "since random forests and sequential deep learning models both require preprocessing we don't need to keep track of separate scaled and unscaled data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Loan_Status              2\nTerm                     2\nYears_in_current_job    11\nHome_Ownership           4\nPurpose                  7\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#generate categorical variable list \n",
    "loan_cat = loans_df.dtypes[loans_df.dtypes==\"object\"].index.tolist()\n",
    "#check number of unique values\n",
    "loans_df[loan_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10+_years    13149\n2_years       3225\n3_years       2997\n&lt;_1_year      2699\n5_years       2487\n4_years       2286\n1_year        2247\n6_years       2109\n7_years       2082\n8_years       1675\n9_years       1467\nName: Years_in_current_job, dtype: int64"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#years in current job has 11 unique values. we should check the number of data points for each unique value to find out if any categorical variables need to be bucketed  \n",
    "\n",
    "loans_df.Years_in_current_job.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Loan_Status_Fully_Paid  Loan_Status_Not_Paid  Term_Long_Term  \\\n0                     1.0                   0.0             0.0   \n1                     1.0                   0.0             0.0   \n2                     1.0                   0.0             0.0   \n3                     1.0                   0.0             0.0   \n4                     1.0                   0.0             0.0   \n\n   Term_Short_Term  Years_in_current_job_10+_years  \\\n0              1.0                             0.0   \n1              1.0                             0.0   \n2              1.0                             0.0   \n3              1.0                             0.0   \n4              1.0                             0.0   \n\n   Years_in_current_job_1_year  Years_in_current_job_2_years  \\\n0                          0.0                           0.0   \n1                          0.0                           0.0   \n2                          0.0                           1.0   \n3                          0.0                           0.0   \n4                          0.0                           0.0   \n\n   Years_in_current_job_3_years  Years_in_current_job_4_years  \\\n0                           0.0                           0.0   \n1                           0.0                           0.0   \n2                           0.0                           0.0   \n3                           1.0                           0.0   \n4                           0.0                           0.0   \n\n   Years_in_current_job_5_years  ...  Home_Ownership_Home_Mortgage  \\\n0                           0.0  ...                           0.0   \n1                           0.0  ...                           1.0   \n2                           0.0  ...                           0.0   \n3                           0.0  ...                           0.0   \n4                           0.0  ...                           0.0   \n\n   Home_Ownership_Own_Home  Home_Ownership_Rent  Purpose_Business_Loan  \\\n0                      1.0                  0.0                    0.0   \n1                      0.0                  0.0                    0.0   \n2                      0.0                  1.0                    0.0   \n3                      0.0                  1.0                    0.0   \n4                      1.0                  0.0                    0.0   \n\n   Purpose_Buy_House  Purpose_Buy_a_Car  Purpose_Debt_Consolidation  \\\n0                0.0                0.0                         1.0   \n1                0.0                0.0                         1.0   \n2                0.0                0.0                         1.0   \n3                0.0                0.0                         1.0   \n4                0.0                0.0                         1.0   \n\n   Purpose_Home_Improvements  Purpose_Medical_Bills  Purpose_Other  \n0                        0.0                    0.0            0.0  \n1                        0.0                    0.0            0.0  \n2                        0.0                    0.0            0.0  \n3                        0.0                    0.0            0.0  \n4                        0.0                    0.0            0.0  \n\n[5 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loan_Status_Fully_Paid</th>\n      <th>Loan_Status_Not_Paid</th>\n      <th>Term_Long_Term</th>\n      <th>Term_Short_Term</th>\n      <th>Years_in_current_job_10+_years</th>\n      <th>Years_in_current_job_1_year</th>\n      <th>Years_in_current_job_2_years</th>\n      <th>Years_in_current_job_3_years</th>\n      <th>Years_in_current_job_4_years</th>\n      <th>Years_in_current_job_5_years</th>\n      <th>...</th>\n      <th>Home_Ownership_Home_Mortgage</th>\n      <th>Home_Ownership_Own_Home</th>\n      <th>Home_Ownership_Rent</th>\n      <th>Purpose_Business_Loan</th>\n      <th>Purpose_Buy_House</th>\n      <th>Purpose_Buy_a_Car</th>\n      <th>Purpose_Debt_Consolidation</th>\n      <th>Purpose_Home_Improvements</th>\n      <th>Purpose_Medical_Bills</th>\n      <th>Purpose_Other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#each category has a significant number of values. we don't want to bucket these and potentially confuse the model\n",
    "\n",
    "#create onehotencoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "#fit and transform using categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(loans_df[loan_cat]))\n",
    "\n",
    "#add encoded variables to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(loan_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Current_Loan_Amount  Credit_Score  Annual_Income  Monthly_Debt  \\\n0             99999999         741.0      2231892.0      29200.53   \n1               217646         730.0      1184194.0      10855.08   \n2               548746         678.0      2559110.0      18660.28   \n3             99999999         728.0       714628.0      11851.06   \n4             99999999         740.0       776188.0      11578.22   \n\n   Years_of_Credit_History  Months_since_last_delinquent  \\\n0                     14.9                          29.0   \n1                     19.6                          10.0   \n2                     22.6                          33.0   \n3                     16.0                          76.0   \n4                      8.5                          25.0   \n\n   Number_of_Open_Accounts  Number_of_Credit_Problems  Current_Credit_Balance  \\\n0                       18                          1                  297996   \n1                       13                          1                  122170   \n2                        4                          0                  437171   \n3                       16                          0                  203965   \n4                        6                          0                  134083   \n\n   Maximum_Open_Credit  ...  Home_Ownership_Home_Mortgage  \\\n0             750090.0  ...                           0.0   \n1             272052.0  ...                           1.0   \n2             555038.0  ...                           0.0   \n3             289784.0  ...                           0.0   \n4             220220.0  ...                           0.0   \n\n   Home_Ownership_Own_Home  Home_Ownership_Rent  Purpose_Business_Loan  \\\n0                      1.0                  0.0                    0.0   \n1                      0.0                  0.0                    0.0   \n2                      0.0                  1.0                    0.0   \n3                      0.0                  1.0                    0.0   \n4                      1.0                  0.0                    0.0   \n\n   Purpose_Buy_House  Purpose_Buy_a_Car  Purpose_Debt_Consolidation  \\\n0                0.0                0.0                         1.0   \n1                0.0                0.0                         1.0   \n2                0.0                0.0                         1.0   \n3                0.0                0.0                         1.0   \n4                0.0                0.0                         1.0   \n\n   Purpose_Home_Improvements  Purpose_Medical_Bills  Purpose_Other  \n0                        0.0                    0.0            0.0  \n1                        0.0                    0.0            0.0  \n2                        0.0                    0.0            0.0  \n3                        0.0                    0.0            0.0  \n4                        0.0                    0.0            0.0  \n\n[5 rows x 38 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Current_Loan_Amount</th>\n      <th>Credit_Score</th>\n      <th>Annual_Income</th>\n      <th>Monthly_Debt</th>\n      <th>Years_of_Credit_History</th>\n      <th>Months_since_last_delinquent</th>\n      <th>Number_of_Open_Accounts</th>\n      <th>Number_of_Credit_Problems</th>\n      <th>Current_Credit_Balance</th>\n      <th>Maximum_Open_Credit</th>\n      <th>...</th>\n      <th>Home_Ownership_Home_Mortgage</th>\n      <th>Home_Ownership_Own_Home</th>\n      <th>Home_Ownership_Rent</th>\n      <th>Purpose_Business_Loan</th>\n      <th>Purpose_Buy_House</th>\n      <th>Purpose_Buy_a_Car</th>\n      <th>Purpose_Debt_Consolidation</th>\n      <th>Purpose_Home_Improvements</th>\n      <th>Purpose_Medical_Bills</th>\n      <th>Purpose_Other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>99999999</td>\n      <td>741.0</td>\n      <td>2231892.0</td>\n      <td>29200.53</td>\n      <td>14.9</td>\n      <td>29.0</td>\n      <td>18</td>\n      <td>1</td>\n      <td>297996</td>\n      <td>750090.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>217646</td>\n      <td>730.0</td>\n      <td>1184194.0</td>\n      <td>10855.08</td>\n      <td>19.6</td>\n      <td>10.0</td>\n      <td>13</td>\n      <td>1</td>\n      <td>122170</td>\n      <td>272052.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>548746</td>\n      <td>678.0</td>\n      <td>2559110.0</td>\n      <td>18660.28</td>\n      <td>22.6</td>\n      <td>33.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>437171</td>\n      <td>555038.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>99999999</td>\n      <td>728.0</td>\n      <td>714628.0</td>\n      <td>11851.06</td>\n      <td>16.0</td>\n      <td>76.0</td>\n      <td>16</td>\n      <td>0</td>\n      <td>203965</td>\n      <td>289784.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>99999999</td>\n      <td>740.0</td>\n      <td>776188.0</td>\n      <td>11578.22</td>\n      <td>8.5</td>\n      <td>25.0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>134083</td>\n      <td>220220.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 38 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#merge encoded features and drop originals\n",
    "loans_df = loans_df.merge(encode_df, left_index=True, right_index=True)\n",
    "loans_df = loans_df.drop(loan_cat,1)\n",
    "loans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove loan status target from feature data\n",
    "y = loans_df.Loan_Status_Fully_Paid.values\n",
    "X = loans_df.drop(columns=[\"Loan_Status_Fully_Paid\", \"Loan_Status_Not_Paid\"]).values\n",
    "\n",
    "#split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify=y)\n",
    "\n",
    "#create standardscaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#fit the scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "#scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Random forest predictive accuracy: 0.849\n"
    }
   ],
   "source": [
    "#create random forest model. 128 estimators is the largest number of estimators we want to use in a model \n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=78)\n",
    "\n",
    "#fit the model \n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "#evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\"Random forest predictive accuracy: {accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 24\n",
    "hidden_nodes_layer2 = 12\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#add first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "#add second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "#add output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "#compile the model and customize metrics \n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 27317 samples\nEpoch 1/50\n27317/27317 [==============================] - 5s 194us/sample - loss: 0.4197 - accuracy: 0.8364\nEpoch 2/50\n27317/27317 [==============================] - 4s 137us/sample - loss: 0.3860 - accuracy: 0.8490\nEpoch 3/50\n27317/27317 [==============================] - 3s 107us/sample - loss: 0.3822 - accuracy: 0.8494\nEpoch 4/50\n27317/27317 [==============================] - 3s 124us/sample - loss: 0.3800 - accuracy: 0.8491\nEpoch 5/50\n27317/27317 [==============================] - 3s 122us/sample - loss: 0.3786 - accuracy: 0.8494\nEpoch 6/50\n27317/27317 [==============================] - 3s 113us/sample - loss: 0.3772 - accuracy: 0.8494\nEpoch 7/50\n27317/27317 [==============================] - 4s 141us/sample - loss: 0.3766 - accuracy: 0.8495\nEpoch 8/50\n27317/27317 [==============================] - 3s 127us/sample - loss: 0.3761 - accuracy: 0.8495\nEpoch 9/50\n27317/27317 [==============================] - 3s 111us/sample - loss: 0.3753 - accuracy: 0.8493\nEpoch 10/50\n27317/27317 [==============================] - 3s 103us/sample - loss: 0.3748 - accuracy: 0.8495\nEpoch 11/50\n27317/27317 [==============================] - 3s 105us/sample - loss: 0.3743 - accuracy: 0.8498\nEpoch 12/50\n27317/27317 [==============================] - 3s 125us/sample - loss: 0.3737 - accuracy: 0.8497\nEpoch 13/50\n27317/27317 [==============================] - 3s 126us/sample - loss: 0.3730 - accuracy: 0.8497\nEpoch 14/50\n27317/27317 [==============================] - 3s 123us/sample - loss: 0.3728 - accuracy: 0.8496\nEpoch 15/50\n27317/27317 [==============================] - 3s 119us/sample - loss: 0.3721 - accuracy: 0.8499\nEpoch 16/50\n27317/27317 [==============================] - 3s 117us/sample - loss: 0.3717 - accuracy: 0.8499\nEpoch 17/50\n27317/27317 [==============================] - 3s 119us/sample - loss: 0.3715 - accuracy: 0.8500\nEpoch 18/50\n27317/27317 [==============================] - 3s 114us/sample - loss: 0.3711 - accuracy: 0.8501\nEpoch 19/50\n27317/27317 [==============================] - 3s 114us/sample - loss: 0.3707 - accuracy: 0.8502\nEpoch 20/50\n27317/27317 [==============================] - 3s 119us/sample - loss: 0.3706 - accuracy: 0.8499\nEpoch 21/50\n27317/27317 [==============================] - 3s 125us/sample - loss: 0.3698 - accuracy: 0.8502\nEpoch 22/50\n27317/27317 [==============================] - 3s 103us/sample - loss: 0.3699 - accuracy: 0.8496\nEpoch 23/50\n27317/27317 [==============================] - 3s 103us/sample - loss: 0.3697 - accuracy: 0.8501\nEpoch 24/50\n27317/27317 [==============================] - 3s 103us/sample - loss: 0.3691 - accuracy: 0.8501\nEpoch 25/50\n27317/27317 [==============================] - 3s 106us/sample - loss: 0.3687 - accuracy: 0.8505\nEpoch 26/50\n27317/27317 [==============================] - 3s 112us/sample - loss: 0.3690 - accuracy: 0.8504\nEpoch 27/50\n27317/27317 [==============================] - 3s 115us/sample - loss: 0.3676 - accuracy: 0.8510\nEpoch 28/50\n27317/27317 [==============================] - 3s 107us/sample - loss: 0.3680 - accuracy: 0.8505\nEpoch 29/50\n27317/27317 [==============================] - 3s 110us/sample - loss: 0.3677 - accuracy: 0.8504\nEpoch 30/50\n27317/27317 [==============================] - 3s 113us/sample - loss: 0.3673 - accuracy: 0.8506\nEpoch 31/50\n27317/27317 [==============================] - 3s 110us/sample - loss: 0.3670 - accuracy: 0.8507\nEpoch 32/50\n27317/27317 [==============================] - 3s 124us/sample - loss: 0.3665 - accuracy: 0.8507\nEpoch 33/50\n27317/27317 [==============================] - 3s 126us/sample - loss: 0.3662 - accuracy: 0.8506\nEpoch 34/50\n27317/27317 [==============================] - 3s 126us/sample - loss: 0.3660 - accuracy: 0.8508\nEpoch 35/50\n27317/27317 [==============================] - 3s 125us/sample - loss: 0.3663 - accuracy: 0.8506\nEpoch 36/50\n27317/27317 [==============================] - 3s 112us/sample - loss: 0.3656 - accuracy: 0.8512\nEpoch 37/50\n27317/27317 [==============================] - 3s 120us/sample - loss: 0.3658 - accuracy: 0.8514\nEpoch 38/50\n27317/27317 [==============================] - 4s 131us/sample - loss: 0.3653 - accuracy: 0.8509\nEpoch 39/50\n27317/27317 [==============================] - 3s 123us/sample - loss: 0.3650 - accuracy: 0.8510\nEpoch 40/50\n27317/27317 [==============================] - 3s 117us/sample - loss: 0.3647 - accuracy: 0.8508\nEpoch 41/50\n27317/27317 [==============================] - 3s 113us/sample - loss: 0.3648 - accuracy: 0.8513\nEpoch 42/50\n27317/27317 [==============================] - 3s 119us/sample - loss: 0.3643 - accuracy: 0.8510\nEpoch 43/50\n27317/27317 [==============================] - 3s 103us/sample - loss: 0.3643 - accuracy: 0.8511\nEpoch 44/50\n27317/27317 [==============================] - 3s 118us/sample - loss: 0.3642 - accuracy: 0.8517\nEpoch 45/50\n27317/27317 [==============================] - 4s 130us/sample - loss: 0.3635 - accuracy: 0.8521\nEpoch 46/50\n27317/27317 [==============================] - 3s 114us/sample - loss: 0.3638 - accuracy: 0.8518\nEpoch 47/50\n27317/27317 [==============================] - 3s 105us/sample - loss: 0.3634 - accuracy: 0.8515\nEpoch 48/50\n27317/27317 [==============================] - 3s 119us/sample - loss: 0.3633 - accuracy: 0.8518\nEpoch 49/50\n27317/27317 [==============================] - 3s 122us/sample - loss: 0.3630 - accuracy: 0.8520\nEpoch 50/50\n27317/27317 [==============================] - 4s 132us/sample - loss: 0.3627 - accuracy: 0.8521\n9106/1 - 1s - loss: 0.4250 - accuracy: 0.8452\nLoss: 0.38881195106009925, Accuracy: 0.8451570272445679\n"
    }
   ],
   "source": [
    "#train the deep nn\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "#evaluate the model \n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "source": [
    "comparing both models accuracy scores we see that their output is very similar. both were able to predict whether or not a loan will be repaid over 80% of the time. Although their performance was similar, the deep learning model took minutes to train while the random forest took seconds. The random forest was able to achieve comparable results with less code and faster performance. If a dataset is tabular a random forest is a great place to start. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}