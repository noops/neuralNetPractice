{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit ('PythonData': conda)",
   "display_name": "Python 3.7.7 64-bit ('PythonData': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6629937ca33c91e24171fb9c2c6e8adc4c28b335a7e363e22452b0d874202ae3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "SVM's are great at binary classification, and have an advantage over neural networks when it comes to binary classification problems. In straight forward binary classification problems SVM will outperform even a well trained deep learning model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import tensorflow as tf\n",
    "from path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Age       Job Marital_Status               Education Default_Credit  \\\n0   56     other        married       Primary_Education             no   \n1   37  services        married     Secondary_Education             no   \n2   40     admin        married       Primary_Education             no   \n3   56  services        married     Secondary_Education             no   \n4   59     admin        married  Professional_Education             no   \n\n  Housing_Loan Personal_Loan Subscribed  \n0           no            no         no  \n1          yes            no         no  \n2           no            no         no  \n3           no           yes         no  \n4           no            no         no  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Job</th>\n      <th>Marital_Status</th>\n      <th>Education</th>\n      <th>Default_Credit</th>\n      <th>Housing_Loan</th>\n      <th>Personal_Loan</th>\n      <th>Subscribed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>other</td>\n      <td>married</td>\n      <td>Primary_Education</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>services</td>\n      <td>married</td>\n      <td>Secondary_Education</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>40</td>\n      <td>admin</td>\n      <td>married</td>\n      <td>Primary_Education</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>services</td>\n      <td>married</td>\n      <td>Secondary_Education</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59</td>\n      <td>admin</td>\n      <td>married</td>\n      <td>Professional_Education</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "#load data\n",
    "file_path = Path(\"../Resources/bank_telemarketing.csv\")\n",
    "tele_df = pd.read_csv(file_path)\n",
    "tele_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Job               9\nMarital_Status    3\nEducation         4\nDefault_Credit    2\nHousing_Loan      2\nPersonal_Loan     2\nSubscribed        2\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#encode categorical variables using OneHotEncoder\n",
    "\n",
    "#generate categorical variable list\n",
    "tele_cat = tele_df.dtypes[tele_df.dtypes==\"object\"].index.tolist()\n",
    "\n",
    "#check number of unique values\n",
    "tele_df[tele_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Job_admin  Job_blue-collar  Job_entrepreneur  Job_management  Job_other  \\\n0        0.0              0.0               0.0             0.0        1.0   \n1        0.0              0.0               0.0             0.0        0.0   \n2        1.0              0.0               0.0             0.0        0.0   \n3        0.0              0.0               0.0             0.0        0.0   \n4        1.0              0.0               0.0             0.0        0.0   \n\n   Job_retired  Job_self-employed  Job_services  Job_technician  \\\n0          0.0                0.0           0.0             0.0   \n1          0.0                0.0           1.0             0.0   \n2          0.0                0.0           0.0             0.0   \n3          0.0                0.0           1.0             0.0   \n4          0.0                0.0           0.0             0.0   \n\n   Marital_Status_divorced  ...  Education_Secondary_Education  \\\n0                      0.0  ...                            0.0   \n1                      0.0  ...                            1.0   \n2                      0.0  ...                            0.0   \n3                      0.0  ...                            1.0   \n4                      0.0  ...                            0.0   \n\n   Education_Tertiary_Education  Default_Credit_no  Default_Credit_yes  \\\n0                           0.0                1.0                 0.0   \n1                           0.0                1.0                 0.0   \n2                           0.0                1.0                 0.0   \n3                           0.0                1.0                 0.0   \n4                           0.0                1.0                 0.0   \n\n   Housing_Loan_no  Housing_Loan_yes  Personal_Loan_no  Personal_Loan_yes  \\\n0              1.0               0.0               1.0                0.0   \n1              0.0               1.0               1.0                0.0   \n2              1.0               0.0               1.0                0.0   \n3              1.0               0.0               0.0                1.0   \n4              1.0               0.0               1.0                0.0   \n\n   Subscribed_no  Subscribed_yes  \n0            1.0             0.0  \n1            1.0             0.0  \n2            1.0             0.0  \n3            1.0             0.0  \n4            1.0             0.0  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Job_admin</th>\n      <th>Job_blue-collar</th>\n      <th>Job_entrepreneur</th>\n      <th>Job_management</th>\n      <th>Job_other</th>\n      <th>Job_retired</th>\n      <th>Job_self-employed</th>\n      <th>Job_services</th>\n      <th>Job_technician</th>\n      <th>Marital_Status_divorced</th>\n      <th>...</th>\n      <th>Education_Secondary_Education</th>\n      <th>Education_Tertiary_Education</th>\n      <th>Default_Credit_no</th>\n      <th>Default_Credit_yes</th>\n      <th>Housing_Loan_no</th>\n      <th>Housing_Loan_yes</th>\n      <th>Personal_Loan_no</th>\n      <th>Personal_Loan_yes</th>\n      <th>Subscribed_no</th>\n      <th>Subscribed_yes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#no variables require bucketing \n",
    "\n",
    "#create onehotencoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "#fit and transform \n",
    "encode_df = pd.DataFrame(enc.fit_transform(tele_df[tele_cat]))\n",
    "\n",
    "#add the encoded variable names to the dataframe \n",
    "encode_df.columns = enc.get_feature_names(tele_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Age  Job_admin  Job_blue-collar  Job_entrepreneur  Job_management  \\\n0   56        0.0              0.0               0.0             0.0   \n1   37        0.0              0.0               0.0             0.0   \n2   40        1.0              0.0               0.0             0.0   \n3   56        0.0              0.0               0.0             0.0   \n4   59        1.0              0.0               0.0             0.0   \n\n   Job_other  Job_retired  Job_self-employed  Job_services  Job_technician  \\\n0        1.0          0.0                0.0           0.0             0.0   \n1        0.0          0.0                0.0           1.0             0.0   \n2        0.0          0.0                0.0           0.0             0.0   \n3        0.0          0.0                0.0           1.0             0.0   \n4        0.0          0.0                0.0           0.0             0.0   \n\n   ...  Education_Secondary_Education  Education_Tertiary_Education  \\\n0  ...                            0.0                           0.0   \n1  ...                            1.0                           0.0   \n2  ...                            0.0                           0.0   \n3  ...                            1.0                           0.0   \n4  ...                            0.0                           0.0   \n\n   Default_Credit_no  Default_Credit_yes  Housing_Loan_no  Housing_Loan_yes  \\\n0                1.0                 0.0              1.0               0.0   \n1                1.0                 0.0              0.0               1.0   \n2                1.0                 0.0              1.0               0.0   \n3                1.0                 0.0              1.0               0.0   \n4                1.0                 0.0              1.0               0.0   \n\n   Personal_Loan_no  Personal_Loan_yes  Subscribed_no  Subscribed_yes  \n0               1.0                0.0            1.0             0.0  \n1               1.0                0.0            1.0             0.0  \n2               1.0                0.0            1.0             0.0  \n3               0.0                1.0            1.0             0.0  \n4               1.0                0.0            1.0             0.0  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Job_admin</th>\n      <th>Job_blue-collar</th>\n      <th>Job_entrepreneur</th>\n      <th>Job_management</th>\n      <th>Job_other</th>\n      <th>Job_retired</th>\n      <th>Job_self-employed</th>\n      <th>Job_services</th>\n      <th>Job_technician</th>\n      <th>...</th>\n      <th>Education_Secondary_Education</th>\n      <th>Education_Tertiary_Education</th>\n      <th>Default_Credit_no</th>\n      <th>Default_Credit_yes</th>\n      <th>Housing_Loan_no</th>\n      <th>Housing_Loan_yes</th>\n      <th>Personal_Loan_no</th>\n      <th>Personal_Loan_yes</th>\n      <th>Subscribed_no</th>\n      <th>Subscribed_yes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>40</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#merge encoded features and drop originals\n",
    "tele_df = tele_df.merge(encode_df, left_index=True, right_index=True)\n",
    "tele_df = tele_df.drop(tele_cat,1)\n",
    "tele_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove loan status target from feature data\n",
    "y = tele_df.Subscribed_yes.values\n",
    "X = tele_df.drop(columns=[\"Subscribed_no\", \"Subscribed_yes\"]).values\n",
    "\n",
    "#split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify=y)\n",
    "\n",
    "#create standardscaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#fit the scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "#scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create svm model\n",
    "svm = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SVC(kernel=&#39;linear&#39;)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#train the svm model\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SVM model accuracy: 0.873\n"
    }
   ],
   "source": [
    "#evaluate the svm model\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "print(f\"SVM model accuracy: {accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 10\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#add first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "#add second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "#add output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "#compile the model and customize metrics \n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 22857 samples\nEpoch 1/50\n22857/22857 [==============================] - 5s 218us/sample - loss: 0.4054 - accuracy: 0.8679\nEpoch 2/50\n22857/22857 [==============================] - 4s 162us/sample - loss: 0.3726 - accuracy: 0.8735\nEpoch 3/50\n22857/22857 [==============================] - 3s 136us/sample - loss: 0.3703 - accuracy: 0.8735\nEpoch 4/50\n22857/22857 [==============================] - 3s 133us/sample - loss: 0.3691 - accuracy: 0.8735\nEpoch 5/50\n22857/22857 [==============================] - 3s 120us/sample - loss: 0.3683 - accuracy: 0.8735\nEpoch 6/50\n22857/22857 [==============================] - 3s 120us/sample - loss: 0.3676 - accuracy: 0.8735\nEpoch 7/50\n22857/22857 [==============================] - 3s 126us/sample - loss: 0.3671 - accuracy: 0.8735\nEpoch 8/50\n22857/22857 [==============================] - 3s 115us/sample - loss: 0.3667 - accuracy: 0.8735\nEpoch 9/50\n22857/22857 [==============================] - 3s 115us/sample - loss: 0.3662 - accuracy: 0.8735\nEpoch 10/50\n22857/22857 [==============================] - 3s 120us/sample - loss: 0.3660 - accuracy: 0.8735\nEpoch 11/50\n22857/22857 [==============================] - 3s 149us/sample - loss: 0.3657 - accuracy: 0.8735\nEpoch 12/50\n22857/22857 [==============================] - 3s 128us/sample - loss: 0.3653 - accuracy: 0.8735\nEpoch 13/50\n22857/22857 [==============================] - 3s 118us/sample - loss: 0.3652 - accuracy: 0.8735\nEpoch 14/50\n22857/22857 [==============================] - 3s 120us/sample - loss: 0.3651 - accuracy: 0.8735\nEpoch 15/50\n22857/22857 [==============================] - 2s 108us/sample - loss: 0.3648 - accuracy: 0.8735\nEpoch 16/50\n22857/22857 [==============================] - 3s 113us/sample - loss: 0.3648 - accuracy: 0.8735\nEpoch 17/50\n22857/22857 [==============================] - 3s 111us/sample - loss: 0.3647 - accuracy: 0.8735\nEpoch 18/50\n22857/22857 [==============================] - 3s 116us/sample - loss: 0.3646 - accuracy: 0.8735\nEpoch 19/50\n22857/22857 [==============================] - 3s 111us/sample - loss: 0.3643 - accuracy: 0.8735\nEpoch 20/50\n22857/22857 [==============================] - 3s 115us/sample - loss: 0.3643 - accuracy: 0.8735\nEpoch 21/50\n22857/22857 [==============================] - 3s 113us/sample - loss: 0.3640 - accuracy: 0.8735\nEpoch 22/50\n22857/22857 [==============================] - 3s 127us/sample - loss: 0.3640 - accuracy: 0.8735\nEpoch 23/50\n22857/22857 [==============================] - 3s 115us/sample - loss: 0.3638 - accuracy: 0.8735\nEpoch 24/50\n22857/22857 [==============================] - 3s 110us/sample - loss: 0.3637 - accuracy: 0.8735\nEpoch 25/50\n22857/22857 [==============================] - 3s 110us/sample - loss: 0.3637 - accuracy: 0.8735\nEpoch 26/50\n22857/22857 [==============================] - 3s 113us/sample - loss: 0.3634 - accuracy: 0.8735\nEpoch 27/50\n22857/22857 [==============================] - 3s 119us/sample - loss: 0.3630 - accuracy: 0.8735\nEpoch 28/50\n22857/22857 [==============================] - 3s 112us/sample - loss: 0.3632 - accuracy: 0.8735\nEpoch 29/50\n22857/22857 [==============================] - 2s 109us/sample - loss: 0.3633 - accuracy: 0.8735\nEpoch 30/50\n22857/22857 [==============================] - 2s 107us/sample - loss: 0.3629 - accuracy: 0.8735\nEpoch 31/50\n22857/22857 [==============================] - 3s 110us/sample - loss: 0.3628 - accuracy: 0.8735\nEpoch 32/50\n22857/22857 [==============================] - 2s 109us/sample - loss: 0.3628 - accuracy: 0.8735\nEpoch 33/50\n22857/22857 [==============================] - 3s 112us/sample - loss: 0.3628 - accuracy: 0.8735\nEpoch 34/50\n22857/22857 [==============================] - 3s 110us/sample - loss: 0.3627 - accuracy: 0.8735\nEpoch 35/50\n22857/22857 [==============================] - 3s 112us/sample - loss: 0.3626 - accuracy: 0.8735\nEpoch 36/50\n22857/22857 [==============================] - 2s 108us/sample - loss: 0.3626 - accuracy: 0.8735\nEpoch 37/50\n22857/22857 [==============================] - 2s 109us/sample - loss: 0.3626 - accuracy: 0.8735\nEpoch 38/50\n22857/22857 [==============================] - 3s 114us/sample - loss: 0.3621 - accuracy: 0.8735\nEpoch 39/50\n22857/22857 [==============================] - 3s 117us/sample - loss: 0.3626 - accuracy: 0.8735\nEpoch 40/50\n22857/22857 [==============================] - 2s 108us/sample - loss: 0.3624 - accuracy: 0.8735\nEpoch 41/50\n22857/22857 [==============================] - 3s 120us/sample - loss: 0.3623 - accuracy: 0.8735\nEpoch 42/50\n22857/22857 [==============================] - 3s 110us/sample - loss: 0.3623 - accuracy: 0.8735\nEpoch 43/50\n22857/22857 [==============================] - 3s 113us/sample - loss: 0.3625 - accuracy: 0.8735\nEpoch 44/50\n22857/22857 [==============================] - 3s 110us/sample - loss: 0.3623 - accuracy: 0.8735\nEpoch 45/50\n22857/22857 [==============================] - 3s 112us/sample - loss: 0.3623 - accuracy: 0.8735\nEpoch 46/50\n22857/22857 [==============================] - 3s 114us/sample - loss: 0.3623 - accuracy: 0.8735\nEpoch 47/50\n22857/22857 [==============================] - 3s 113us/sample - loss: 0.3621 - accuracy: 0.8735\nEpoch 48/50\n22857/22857 [==============================] - 3s 113us/sample - loss: 0.3623 - accuracy: 0.8735\nEpoch 49/50\n22857/22857 [==============================] - 3s 112us/sample - loss: 0.3621 - accuracy: 0.8735\nEpoch 50/50\n22857/22857 [==============================] - 3s 115us/sample - loss: 0.3623 - accuracy: 0.8735\n7620/1 - 1s - loss: 0.5460 - accuracy: 0.8735\nLoss: 0.3693818407734548, Accuracy: 0.8734908103942871\n"
    }
   ],
   "source": [
    "#train the deep nn\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "#evaluate the model \n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "source": [
    "both models achieved an accuracy score of around 87%. Both models also take a similar amount of time to train on the input data. the only real noticeable difference is the amount of code needed to implement. The SVM requires much less code than the deep learning model. For strictly binary classification problems the SVM (support vector machine) is the better choice. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}